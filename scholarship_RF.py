# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i217lxtSOJIsyjXR1rnfHVFa2GbPSsuT
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

file_path = 'dataset_combined.csv'
df = pd.read_csv(file_path)

# Display basic information about the dataset
print(df.info())

# Display the first few rows of the dataset
print(df.head())

# Display summary statistics of numeric columns
print(df.describe())

downsampled_df = df.sample(n=20000, random_state=42)  # Use a specific random state for reproducibility
df = downsampled_df

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

import warnings
warnings.filterwarnings("ignore")

sns.set_palette("rocket")

from sklearn.preprocessing import OrdinalEncoder

from sklearn.model_selection import train_test_split

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

import joblib

def get_graph_data(scholarship_df, feature_col):

    df_0 = scholarship_df[ scholarship_df["Outcome"]==0 ][[feature_col,"Outcome"]].groupby(feature_col).count()
    df_0 = df_0.reset_index()

    df_1 = scholarship_df[ scholarship_df["Outcome"]==1 ][[feature_col,"Outcome"]].groupby(feature_col).count()
    df_1 = df_1.reset_index()

    df = pd.DataFrame()
    df[feature_col] = df_0[feature_col]

    df["Outcome=0"] = df_0["Outcome"]
    df["Outcome=1"] = df_1["Outcome"]

    df["Outcome_Total"] = df["Outcome=0"] + df["Outcome=1"]
    df["Outcome=0 %"] = ( df["Outcome=0"] / df["Outcome_Total"] ) * 100
    df["Outcome=1 %"] = ( df["Outcome=1"] / df["Outcome_Total"] ) * 100

    return df

scholarship_df = df

df_education = get_graph_data(scholarship_df, "Education Qualification")
ax = sns.barplot(data=df_education, x="Education Qualification", y="Outcome=1 %")
plt.xlabel("Education Qualification")
plt.ylabel("% of Scholarships Approved")
plt.show()

df_gender = get_graph_data(scholarship_df, "Gender")
ax = sns.barplot(data=df_gender, x="Gender", y="Outcome=1 %")
ax.bar_label(ax.containers[0])
plt.xlabel("Gender")
plt.ylabel("% of Scholarships Approved")
plt.show()

df_community = get_graph_data(scholarship_df, "Community")
df_community
ax = sns.barplot(data=df_community, x="Community", y="Outcome=1 %")
ax.bar_label(ax.containers[0])
plt.xlabel("Community")
plt.ylabel("% of Scholarships Approved")
plt.show()

df_community = get_graph_data(scholarship_df, "Sports")
ax = sns.barplot(data=df_community, x="Sports", y="Outcome=1 %")
ax.bar_label(ax.containers[0])
plt.xlabel("Sports Quota?")
plt.ylabel("% of Scholarships Approved")
plt.show()

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()

scholarship_df['Gender'] = label_encoder.fit_transform(df['Gender'])
scholarship_df['Community'] = label_encoder.fit_transform(df['Community'])
scholarship_df['Disability'] = label_encoder.fit_transform(df['Disability'])
scholarship_df['Sports'] = label_encoder.fit_transform(df['Sports'])
scholarship_df['India'] = label_encoder.fit_transform(df['India'])
scholarship_df['Name'] = label_encoder.fit_transform(df['Name'])
scholarship_df['Religion'] = label_encoder.fit_transform(df['Religion'])
scholarship_df['Income'] = label_encoder.fit_transform(df['Income'])
scholarship_df['Annual-Percentage'] = label_encoder.fit_transform(df['Annual-Percentage'])
scholarship_df['Education Qualification'] = label_encoder.fit_transform(df['Education Qualification'])
scholarship_df['Disability'] = label_encoder.fit_transform(df['Disability'])
scholarship_df['Exservice-men'] = label_encoder.fit_transform(df['Exservice-men'])
scholarship_df['Name'] = label_encoder.fit_transform(df['Name'])

y = scholarship_df["Outcome"]
X = scholarship_df.drop("Outcome", axis=1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)

clf = RandomForestClassifier()

param_grid = {
    'max_depth': [10, None],
    'min_samples_split': [5, 100],
}

grid_search = GridSearchCV(estimator = clf, param_grid = param_grid, cv = 5, n_jobs = -1)
grid_search.fit(X_train, y_train)

best_param = grid_search.best_params_
print(best_param)

clf = RandomForestClassifier(max_depth=10, min_samples_split=100)
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

cm = confusion_matrix(y_test,y_pred)
cm = cm / sum(sum(cm))

sns.heatmap(cm,annot=True,fmt=".1%",
            xticklabels=["Got Scholarship","No Scholarship"],
            yticklabels=["Got Scholarship","No Scholarship"])
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show()

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy = {round(accuracy,2)}")
precision = precision_score(y_test, y_pred)
print(f"Precision = {round(precision,2)}")
recall = recall_score(y_test, y_pred)
print(f"Recall = {round(recall,2)}")
F1_score = f1_score(y_test, y_pred)